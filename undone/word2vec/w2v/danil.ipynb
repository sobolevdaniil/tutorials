{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b3a5c9-8ab2-4584-bacb-580673aa7ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "max_threads = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9fe3f91-efb2-4bcf-b920-e74e1faf6242",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bookcorpus\", num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b85078d-3909-4569-8276-51b09b4f8e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 74004228\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b1fb64-0de0-45e3-9980-ee1102aff163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "018a319e-779b-4aec-a3d2-7e6af103b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(dataset[\"train\"][0]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8e02da-54e5-4ac7-acec-732a4e034771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(samples):\n",
    "  return {\n",
    "      \"processed_text\": [\n",
    "       list(filter(lambda tok: all('a' <= x.lower() <= 'z' for x in tok), tokenizer.tokenize(text)))\n",
    "       for text in samples[\"text\"]\n",
    "      ]\n",
    "  }\n",
    "\n",
    "tokenized_dataset = dataset[\"train\"].map(preprocess_data, batched=True, num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51a6bf05-f4a0-41c8-bdef-305797b90454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'usually , he would be tearing around the living room , playing with his toys .',\n",
       " 'processed_text': ['usually',\n",
       "  'he',\n",
       "  'would',\n",
       "  'be',\n",
       "  'tearing',\n",
       "  'around',\n",
       "  'the',\n",
       "  'living',\n",
       "  'room',\n",
       "  'playing',\n",
       "  'with',\n",
       "  'his',\n",
       "  'toys']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6742c2-fa23-45b4-847e-31bf93546fb0",
   "metadata": {},
   "source": [
    "# Transform text to token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e1809f3-3455-48b4-bd65-f4b0095ac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3471b61-9a8e-4507-957f-a10aca18f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2tokenId.pickle', 'rb') as handle:\n",
    "    word2tokenId = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "574202b1-601f-4947-aaba-bc66d7077a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(samples):\n",
    "  return {\n",
    "      \"tokenized_text\": [\n",
    "                [\n",
    "                    word2tokenId[word] for word in text\n",
    "                ] \n",
    "                for text in samples['processed_text']\n",
    "      ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51a2fb45-7b16-47eb-9ff5-2c9d675492ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.map(tokenize_texts, batched=True, num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abf3c03-aeaf-4493-a6cb-a71c9898d18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'usually , he would be tearing around the living room , playing with his toys .',\n",
       " 'processed_text': ['usually',\n",
       "  'he',\n",
       "  'would',\n",
       "  'be',\n",
       "  'tearing',\n",
       "  'around',\n",
       "  'the',\n",
       "  'living',\n",
       "  'room',\n",
       "  'playing',\n",
       "  'with',\n",
       "  'his',\n",
       "  'toys'],\n",
       " 'tokenized_text': [9424,\n",
       "  82531,\n",
       "  230181,\n",
       "  318116,\n",
       "  431394,\n",
       "  340779,\n",
       "  418995,\n",
       "  479022,\n",
       "  431560,\n",
       "  510338,\n",
       "  382838,\n",
       "  593799,\n",
       "  405334]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18f9891-a1e6-41ce-b5bf-00b2c6846f55",
   "metadata": {},
   "source": [
    "# Word2Vec Class (Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2505e-8ee7-4904-9c7e-be3a7c851b7f",
   "metadata": {},
   "source": [
    "<img src='img1.jpg' width=900, heigth=600>?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feac9d9-bfe5-48d4-9749-841cbb809b9e",
   "metadata": {},
   "source": [
    "<img src='img2.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79dd5e-7bc4-49dc-ab5a-da7c6dd77fe4",
   "metadata": {},
   "source": [
    "<img src='img3.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f788c51-f3cd-4513-b606-8ca7de1cc1be",
   "metadata": {},
   "source": [
    "<img src='img4.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e176547-e006-4c45-9d3d-563a39d20a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb67bc1c-fb64-43ef-95b1-c7a398333bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    def __init__(self, \n",
    "                 embeds_size, \n",
    "                 ctx_window_size, \n",
    "                 negative_samples_count=10, \n",
    "                 path_to_vocab='tokenId2word.pickle'\n",
    "                ):\n",
    "        with open(path_to_vocab, 'rb') as handle:\n",
    "            self.vocab = pickle.load(handle)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.ctx_window_size = ctx_window_size\n",
    "        self.negative_samples_count = negative_samples_count\n",
    "        self.central_embeddings = torch.normal(mean=0, std=1, size=(self.vocab_size, embeds_size), device=torch.device('cuda:0'), requires_grad=True)\n",
    "        self.context_embeddings = torch.normal(mean=0, std=1, size=(self.vocab_size, embeds_size), device=torch.device('cuda:0'), requires_grad=True)\n",
    "\n",
    "    def fit(self, tokenized_dataset, lr=0.01):\n",
    "        for text in tqdm(tokenized_dataset):\n",
    "            for i in range(len(text['tokenized_text'])):\n",
    "                \n",
    "                v = self.central_embeddings[text['tokenized_text'][i]]\n",
    "                for token in text['tokenized_text'][min(0, i-self.ctx_window_size): max(i+self.ctx_window_size, len(text['tokenized_text']))]:\n",
    "                    u = self.context_embeddings[token]\n",
    "\n",
    "                    negative_samples = np.random.randint(0, self.vocab_size, size=self.negative_samples_count)\n",
    "\n",
    "                    J = - u.T @ v + torch.log(torch.sum(torch.exp(self.context_embeddings[negative_samples] @ v)))\n",
    "\n",
    "                    J.backward()\n",
    "                    with torch.no_grad():\n",
    "                        self.central_embeddings[text['tokenized_text'][i]] -= lr * self.central_embeddings.grad[text['tokenized_text'][i]]\n",
    "                        self.context_embeddings[token] -= lr * self.context_embeddings.grad[token]\n",
    "                        self.context_embeddings[negative_samples] -= lr * self.context_embeddings.grad[negative_samples]\n",
    "\n",
    "                    self.context_embeddings.grad.zero_()\n",
    "                    self.central_embeddings.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbca62-80a1-49e3-915a-ffae4576dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(embeds_size=50, ctx_window_size=5)\n",
    "\n",
    "w2v.fit(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea70030-5d0e-46fb-9678-733c59581d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
