{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586209d1-5254-4fcb-b299-1a5b4d58fec3",
   "metadata": {},
   "source": [
    "# Load dataset from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913bcf40-df35-410e-879a-a754e4d03c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.2\n"
     ]
    }
   ],
   "source": [
    "!python3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8269d71-9f43-4a48-83e3-63100d8aec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "max_threads = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5881135-ceea-4ace-9a92-4e05df27249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"bookcorpus\", num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8866ff4-c903-41b9-9015-869946436517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6176e4cc-dc28-4cef-94bc-d24ea1e01372",
   "metadata": {},
   "source": [
    "# Tokenize dataset (with lemmatization) and create vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f4b863-2ddd-4ae3-ae35-a5bf51fc0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72eee762-b696-4172-a7ee-fdf3cd074359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['usually', ',', 'he', 'would', 'be', 'tearing', 'around', 'the', 'living', 'room', ',', 'playing', 'with', 'his', 'toys', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "print(tokenizer.tokenize(dataset[\"train\"][0]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53437ac6-9e0e-4cd4-8d74-bc8c50eaeeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(samples):\n",
    "  return {\n",
    "      \"processed_text\": [\n",
    "       list(filter(lambda tok: all('a' <= x.lower() <= 'z' for x in tok), tokenizer.tokenize(text)))\n",
    "       for text in samples[\"text\"]\n",
    "      ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b4dfb72-1404-437b-b570-804cb3ea2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset[\"train\"].map(preprocess_data, batched=True, num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb27dff-57f1-4d8b-a12b-112c5806d6fb",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'usually , he would be tearing around the living room , playing with his toys .',\n",
       " 'processed_text': ['usually',\n",
       "  'he',\n",
       "  'would',\n",
       "  'be',\n",
       "  'tearing',\n",
       "  'around',\n",
       "  'the',\n",
       "  'living',\n",
       "  'room',\n",
       "  'playing',\n",
       "  'with',\n",
       "  'his',\n",
       "  'toys']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3493b680-802d-47ce-a614-5dc94e2ed34d",
   "metadata": {},
   "source": [
    "### Build vocabulary for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7966cce9-c07c-4c79-83c5-07b5b29d5ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = set()\n",
    "\n",
    "# def build_vocab(sample):\n",
    "#     global vocab\n",
    "#     vocab.update(set(sample[\"processed_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ef9577-c5cb-4681-98dc-6bc052d600b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset.map(build_vocab)\n",
    "\n",
    "# word2tokenId = {word: idx for idx, word in enumerate(vocab)}\n",
    "# tokenId2word = {idx: word for idx, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62145f5b-918c-4255-8cf6-e34805f7d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('word2tokenId.pickle', 'wb') as handle:\n",
    "#     pickle.dump(word2tokenId, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('tokenId2word.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tokenId2word, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264eb64-391a-4dbe-8849-2eb8b57baf53",
   "metadata": {},
   "source": [
    "### Transform text to token ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8af5003e-b3b2-45ef-99f7-39fe3699ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2tokenId.pickle', 'rb') as handle:\n",
    "    word2tokenId = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3938596-f9cc-40a7-a459-ed699b3d021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_texts(samples):\n",
    "  return {\n",
    "      \"tokenized_text\": [\n",
    "                [\n",
    "                    word2tokenId[word] for word in text\n",
    "                ] \n",
    "                for text in samples['processed_text']\n",
    "      ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c5fe4c7-6cef-44ae-bf9f-ef61396983c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.map(tokenize_texts, batched=True, num_proc=max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "845d4b17-6115-4e5c-aab0-7f0ff4930439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'processed_text', 'tokenized_text'],\n",
       "    num_rows: 74004228\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc0782-9703-44cd-8555-bd1e4292b162",
   "metadata": {},
   "source": [
    "# Word2Vec Class (Pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c509ae5-29ec-4e5a-a691-031caba9d99f",
   "metadata": {},
   "source": [
    "<img src='img1.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceed4af-9966-45b6-8bc9-ed0a658bdbf9",
   "metadata": {},
   "source": [
    "<img src='img2.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c55786-fbaa-46a2-8c36-81333c416fbc",
   "metadata": {},
   "source": [
    "<img src='img3.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d888b0ea-6658-4368-b784-ab5ae72cec6e",
   "metadata": {},
   "source": [
    "<img src='img4.jpg' width=900, heigth=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87722ecf-0910-42dc-acac-869675b5606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "import numpy as np\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37cb4d60-4388-449f-a502-a5bd9696ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# распараллелить подсчёт лосса для батча предложений\n",
    "# аккумулировать лосс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8734614-da41-4b41-963f-2024b0627012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(dataset, batch_size):\n",
    "    for i in trange(len(dataset)//batch_size + 1):\n",
    "        yield dataset[i*batch_size:(i+1)*batch_size]['tokenized_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81af3133-a6fc-4b1b-a30f-892bf73eece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec:\n",
    "    def __init__(self, \n",
    "                 embeds_size, \n",
    "                 ctx_window_size, \n",
    "                 negative_samples_count=10, \n",
    "                 path_to_vocab='tokenId2word.pickle'\n",
    "                ):\n",
    "        with open(path_to_vocab, 'rb') as handle:\n",
    "            self.vocab = pickle.load(handle)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.ctx_window_size = ctx_window_size\n",
    "        self.negative_samples_count = negative_samples_count\n",
    "        self.central_embeddings = torch.normal(mean=0, std=1, size=(self.vocab_size, embeds_size), device=torch.device('cuda:0'), requires_grad=True)\n",
    "        self.context_embeddings = torch.normal(mean=0, std=1, size=(self.vocab_size, embeds_size), device=torch.device('cuda:0'), requires_grad=True)\n",
    "\n",
    "    def sentence_process(self, sentence, lr=0.01):\n",
    "        sentence = sentence['tokenized_text']\n",
    "        for c in range(len(sentence)):\n",
    "            for o in range(max(c - self.ctx_window_size//2, 0), min(c + self.ctx_window_size//2, len(sentence)-1)):\n",
    "                context_embeddings.grad.zero_()\n",
    "                central_embeddings.grad.zero_()\n",
    "\n",
    "                negative_samples = np.random.randint(0, high=self.vocab_size, size=self.negative_samples_count)\n",
    "                loss = -(self.context_embeddings[sentence[o]].T@self.central_embeddings[sentence[c]]) + torch.log(torch.sum(torch.exp(self.context_embeddings[negative_samples]@self.central_embeddings[sentence[c]])))\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    self.context_embeddings[sentence[o]] -= lr*self.context_embeddings.grad[sentence[o]]\n",
    "                    self.central_embeddings[sentence[c]] -= lr*self.central_embeddings.grad[sentence[c]]\n",
    "                    for w in negative_samples:\n",
    "                        self.context_embeddings[w] -= lr*self.context_embeddings.grad[w]\n",
    "    \n",
    "    def fit(self, tokenized_dataset, lr=0.01):\n",
    "        # process_map(self.sentence_process, tokenized_dataset, max_workers=max_threads, chunksize=1)\n",
    "        for sentence in tqdm(tokenized_dataset):\n",
    "            sentence = sentence['tokenized_text']\n",
    "            for c in range(len(sentence)):\n",
    "                for o in range(max(c - self.ctx_window_size//2, 0), min(c + self.ctx_window_size//2, len(sentence)-1)):\n",
    "                    negative_samples = np.random.randint(0, high=self.vocab_size, size=self.negative_samples_count)\n",
    "                    loss = -(self.context_embeddings[sentence[o]].T@self.central_embeddings[sentence[c]]) + torch.log(torch.sum(torch.exp(self.context_embeddings[negative_samples]@self.central_embeddings[sentence[c]])))\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        self.context_embeddings[sentence[o]] -= lr*self.context_embeddings.grad[sentence[o]]\n",
    "                        self.central_embeddings[sentence[c]] -= lr*self.central_embeddings.grad[sentence[c]]\n",
    "                        for w in negative_samples:\n",
    "                            self.context_embeddings[w] -= lr*self.context_embeddings.grad[w]\n",
    "\n",
    "                    self.context_embeddings.grad.zero_()\n",
    "                    self.central_embeddings.grad.zero_()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a52c0ae1-167d-4011-a580-240ff7405c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(100, ctx_window_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c65ba6f-1895-4b39-b739-ad90be765bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'processed_text', 'tokenized_text'],\n",
       "    num_rows: 74004228\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d452025-9a71-4729-8bfb-ca6ed6cb60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/74004228 [00:00<?, ?it/s]/tmp/ipykernel_1301/526091490.py:41: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3637.)\n",
      "  loss = -(self.context_embeddings[sentence[o]].T@self.central_embeddings[sentence[c]]) + torch.log(torch.sum(torch.exp(self.context_embeddings[negative_samples]@self.central_embeddings[sentence[c]])))\n",
      "  0%|                                                                         | 58/74004228 [00:55<19689:35:15,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mword2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 41\u001b[0m, in \u001b[0;36mWord2Vec.fit\u001b[0;34m(self, tokenized_dataset, lr)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmax\u001b[39m(c \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx_window_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mmin\u001b[39m(c \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx_window_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentence)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     40\u001b[0m     negative_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnegative_samples_count)\n\u001b[0;32m---> 41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_embeddings[sentence[o]]\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@self\u001b[39m\u001b[38;5;241m.\u001b[39mcentral_embeddings[sentence[c]]) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnegative_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;129;43m@self\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcentral_embeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     43\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "word2vec.fit(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b146b-261e-4bf2-98cd-eecdb7a745a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(self, tokenized_dataset, batch_size, lr=0.01):\n",
    "#     for batch in batch_generator(tokenized_dataset, batch_size=batch_size):\n",
    "#         for sentence in batch:\n",
    "#             for c in range(len(sentence)):\n",
    "#                 for o in range(max(c - ctx_window_size//2, 0), min(c + ctx_window_size//2, len(sentence)-1)):\n",
    "#                     context_embeddings.grad.zero_()\n",
    "#                     central_embeddings.grad.zero_()\n",
    "\n",
    "#                     negative_samples = np.random.randint(0, high=self.vocab_size, size=negative_samples_count)\n",
    "#                     loss = -(self.context_embeddings[sentence[o]].T@self.central_embeddings[sentence[c]]) + torch.log(torch.sum(torch.exp(self.context_embeddings[negative_samples]@self.central_embeddings[sentence[c]])))\n",
    "                    \n",
    "#                     loss.backward()\n",
    "                    \n",
    "#                     self.context_embeddings[sentence[o]] -= lr*self.context_embeddings.grad[sentence[o]]\n",
    "#                     self.central_embeddings[sentence[c]] -= lr*self.central_embeddings.grad[sentence[c]]\n",
    "#                     for w in negative_samples:\n",
    "#                         self.context_embeddings[w] -= lr*self.context_embeddings.grad[w]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env]",
   "language": "python",
   "name": "conda-env-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
